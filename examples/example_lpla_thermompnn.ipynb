{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CB with ThermoMPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "sys.path.append(\"../utilities/\")\n",
    "\n",
    "from cbutils import (\n",
    "    aa_code,\n",
    "    make_consensus_sequence,\n",
    "    setup_aligner,\n",
    "    alignment_to_mapping,\n",
    "    add_scaled_outputs,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select structures and chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbs = {\n",
    "    \"open\": \"../pdbs/lpla/3a7r.pdb\",\n",
    "    \"closed\": \"../pdbs/lpla/1x2g.pdb\",\n",
    "}\n",
    "\n",
    "chains = {\n",
    "    \"open\": \"A\",\n",
    "    \"closed\": \"A\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align sequences, generate mutants, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thermompnn.protein_mpnn_utils import alt_parse_PDB\n",
    "from thermompnn import Mutation, ALPHABET\n",
    "from thermompnn.analysis.thermompnn_benchmarking import load_model\n",
    "\n",
    "import torch\n",
    "\n",
    "#extract sequences from structures\n",
    "thermompnn_seqs = {structure: alt_parse_PDB(pdbs[structure], chains[structure])[0]['seq'] for structure in pdbs}\n",
    "con_seq = make_consensus_sequence(list(thermompnn_seqs.values()))\n",
    "\n",
    "muts = []\n",
    "mut_seqs = []\n",
    "for i, aa in enumerate(con_seq):\n",
    "    for aa_new in aa_code:\n",
    "        if aa_new != aa:\n",
    "            mut_seqs.append(con_seq[:i] + aa_new + con_seq[i + 1 :])\n",
    "            muts.append(f\"{aa}{i+1}{aa_new}\")\n",
    "\n",
    "output_data = pd.DataFrame({\"mut\": muts, \"seq\": mut_seqs})\n",
    "\n",
    "aligner = setup_aligner()\n",
    "thermompnn_alignments = {pdb: aligner.align(con_seq, seq)[0] for pdb, seq in thermompnn_seqs.items()}\n",
    "\n",
    "thermompnn_mappings = {\n",
    "    pdb: alignment_to_mapping(alignment) for pdb, alignment in thermompnn_alignments.items()\n",
    "}\n",
    "\n",
    "#load weights and download weights if not found\n",
    "try:\n",
    "    model = load_model(\"../weights/v_48_020.pt\", \"../weights/thermoMPNN_default.pt\")\n",
    "except FileNotFoundError:\n",
    "    os.makedirs(\"../weights\", exist_ok=True)\n",
    "    tm_url = \"https://raw.githubusercontent.com/andrewxue98/ThermoMPNN/main/weights/thermoMPNN_default.pt\"\n",
    "    pm_url = (\n",
    "        \"https://raw.githubusercontent.com/andrewxue98/ThermoMPNN/main/weights/v_48_020.pt\"\n",
    "    )\n",
    "\n",
    "    response_tm = requests.get(tm_url)\n",
    "    if response_tm.status_code == 200:\n",
    "        with open(\"../weights/thermoMPNN_default.pt\", \"wb\") as f:\n",
    "            f.write(response_tm.content)\n",
    "        print(\"ThermoMPNN weights downloaded successfully!\")\n",
    "    else:\n",
    "        print(f\"Failed to download ThermoMPNN weights. Status code: {response_tm.status_code}\")\n",
    "\n",
    "    response_pm = requests.get(pm_url)\n",
    "    if response_pm.status_code == 200:\n",
    "        with open(\"../weights/v_48_020.pt\", \"wb\") as f:\n",
    "            f.write(response_pm.content)\n",
    "        print(\"ThermoMPNN weights downloaded successfully!\")\n",
    "    else:\n",
    "        print(f\"Failed to download ThermoMPNN weights. Status code: {response_pm.status_code}\")\n",
    "\n",
    "    model = load_model(\"../weights/v_48_020.pt\", \"../weights/thermoMPNN_default.pt\")\n",
    "\n",
    "model = model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#run thermompnn scoring\n",
    "for structure in pdbs:\n",
    "    thermompnn_scores = []\n",
    "    print(f'Running ThermoMPNN on {structure}...')\n",
    "\n",
    "    pdb_fp = pdbs[structure]\n",
    "    chain = chains[structure]\n",
    "\n",
    "    mut_pdb = alt_parse_PDB(pdb_fp, chain)\n",
    "    mutation_list = []\n",
    "\n",
    "    #try to map mutants that we previously generated to thermompnn mutants (should be identical, but might slightly mismatch due to structure handling)\n",
    "    for mut in output_data['mut']:\n",
    "        if mut is None:\n",
    "            mutation_list.append(None)\n",
    "        else: #only accepts single mutants, custom uploads are skipped\n",
    "            wtAA, position, mutAA = str(mut[0]), int(str(mut[1:-1])), str(mut[-1])\n",
    "            position = position - 1 #convert from 1-indexed to zero indexed\n",
    "\n",
    "            if position in thermompnn_mappings[structure]:\n",
    "                position = thermompnn_mappings[structure][position]\n",
    "\n",
    "                assert (\n",
    "                    wtAA in ALPHABET\n",
    "                ), f\"Wild type residue {wtAA} invalid, please try again with one of the following options: {ALPHABET}\"\n",
    "                assert (\n",
    "                    mutAA in ALPHABET\n",
    "                ), f\"Wild type residue {mutAA} invalid, please try again with one of the following options: {ALPHABET}\"\n",
    "\n",
    "                #create thermompnn mutation objects\n",
    "                mutation_obj = Mutation(\n",
    "                    position=position,\n",
    "                    wildtype=wtAA,\n",
    "                    mutation=mutAA,\n",
    "                    ddG=None,\n",
    "                    pdb=mut_pdb[0][\"name\"],\n",
    "                )\n",
    "                mutation_list.append(mutation_obj)\n",
    "            else:\n",
    "                mutation_list.append(None)\n",
    "\n",
    "    pred, _ = model(mut_pdb, mutation_list)\n",
    "\n",
    "    for mut, out in zip(mutation_list, pred):\n",
    "        if mut is not None:\n",
    "            thermompnn_scores.append(-1 * out[\"ddG\"].cpu().item())\n",
    "        else:\n",
    "            thermompnn_scores.append(None)\n",
    "\n",
    "    output_data[f\"thermompnn_{structure}\"] = thermompnn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"thermompnn\"\n",
    "frac_mutants = 0.05\n",
    "\n",
    "# scale columns and calculate bias\n",
    "add_scaled_outputs(output_data, model, state1_col=\"open\", state2_col=\"closed\")\n",
    "\n",
    "# filter mutants by low scores\n",
    "output_data = output_data.dropna(subset=[f\"{model}_state1_bias\"]).sort_values(\n",
    "    by=f\"{model}_state1_bias\", ascending=False\n",
    ")\n",
    "passing_mutants = output_data[\n",
    "    (output_data[f\"{model}_state1_scaled\"] > 0)\n",
    "    | (output_data[f\"{model}_state2_scaled\"] > 0)\n",
    "]\n",
    "nonpassing = output_data[\n",
    "    ~(\n",
    "        (output_data[f\"{model}_state1_scaled\"] > 0)\n",
    "        | (output_data[f\"{model}_state2_scaled\"] > 0)\n",
    "    )\n",
    "]\n",
    "\n",
    "# take top n biased mutants in each direction\n",
    "n_mutants_passing_filter = len(\n",
    "    output_data[\n",
    "        (output_data[f\"{model}_state1_scaled\"] > 0)\n",
    "        | (output_data[f\"{model}_state2_scaled\"] > 0)\n",
    "    ]\n",
    ")\n",
    "n_biased = round((frac_mutants / 2) * n_mutants_passing_filter)\n",
    "\n",
    "state1_biased, neutral, state2_biased = (\n",
    "    passing_mutants[:n_biased],\n",
    "    passing_mutants[n_biased:-n_biased],\n",
    "    passing_mutants[-n_biased:],\n",
    ")\n",
    "\n",
    "s1_set, s2_set, neutral_set, nonpassing_set = (\n",
    "    set(state1_biased[\"mut\"]),\n",
    "    set(state2_biased[\"mut\"]),\n",
    "    set(neutral[\"mut\"]),\n",
    "    set(nonpassing[\"mut\"]),\n",
    ")\n",
    "\n",
    "assignments = []\n",
    "for m in output_data[\"mut\"]:\n",
    "    if m in set(state1_biased[\"mut\"]):\n",
    "        assignment = \"state1\"\n",
    "    elif m in set(state2_biased[\"mut\"]):\n",
    "        assignment = \"state2\"\n",
    "    elif m in neutral_set:\n",
    "        assignment = \"neutral\"\n",
    "    elif m in set(nonpassing[\"mut\"]):\n",
    "        assignment = \"low\"\n",
    "    else:\n",
    "        assignment = None\n",
    "\n",
    "    assignments.append(assignment)\n",
    "\n",
    "# label mutants\n",
    "output_data[f\"{model}_assignment\"] = assignments\n",
    "\n",
    "cmap = {\"state1\": \"red\", \"state2\": \"blue\", \"neutral\": \"grey\", \"low\": \"lightgrey\"}\n",
    "\n",
    "passing = output_data[output_data[f\"{model}_assignment\"] != \"low\"]\n",
    "nonpassing = output_data[output_data[f\"{model}_assignment\"] == \"low\"]\n",
    "\n",
    "state1_cutoff = output_data[output_data[f\"{model}_assignment\"] == \"state1\"][\n",
    "    f\"{model}_state1_bias\"\n",
    "].min()\n",
    "state2_cutoff = output_data[output_data[f\"{model}_assignment\"] == \"state2\"][\n",
    "    f\"{model}_state2_bias\"\n",
    "].min()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Conformational Design Mutants (Top 5% mutants)\")\n",
    "\n",
    "plt.scatter(\n",
    "    passing[f\"{model}_state1_scaled\"],\n",
    "    passing[f\"{model}_state2_scaled\"],\n",
    "    marker=\"o\",\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"black\",\n",
    "    c=[cmap[x] for x in passing[f\"{model}_assignment\"]],\n",
    ")\n",
    "plt.scatter(\n",
    "    nonpassing[f\"{model}_state1_scaled\"],\n",
    "    nonpassing[f\"{model}_state2_scaled\"],\n",
    "    marker=\"o\",\n",
    "    alpha=0.25,\n",
    "    edgecolor=\"black\",\n",
    "    c=[cmap[x] for x in nonpassing[f\"{model}_assignment\"]],\n",
    ")\n",
    "\n",
    "# set limits to be equal on both axes\n",
    "xmin, xmax = plt.xlim()\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "umin, umax = min(xmin, ymin), max(xmax, ymax)\n",
    "plt.xlim(umin, umax)\n",
    "plt.ylim(umin, umax)\n",
    "\n",
    "# show cutoffs\n",
    "plt.plot([umin, 0], [0, 0], color=\"black\")\n",
    "plt.plot([0, 0], [umin, 0], color=\"black\")\n",
    "\n",
    "plt.plot([-state2_cutoff, umax - state2_cutoff], [0, umax], color=\"black\")\n",
    "plt.plot([0, umax], [-state1_cutoff, umax - state1_cutoff], color=\"black\")\n",
    "\n",
    "plt.xlabel(f\"State 1 {model} Score\")\n",
    "plt.ylabel(f\"State 2 {model} Score\")\n",
    "\n",
    "# label each section\n",
    "text_offset = 0.1\n",
    "plt.text(\n",
    "    umax - text_offset,\n",
    "    umax - text_offset,\n",
    "    \"Neutral Mutants\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"top\",\n",
    ")\n",
    "plt.text(\n",
    "    umax - text_offset,\n",
    "    umin + text_offset,\n",
    "    \"State 1 Bias Predicted Mutants\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.text(\n",
    "    umin + text_offset,\n",
    "    umax - text_offset,\n",
    "    \"State 2 Bias Predicted Mutants\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"top\",\n",
    ")\n",
    "plt.text(\n",
    "    umin + text_offset,\n",
    "    umin + text_offset,\n",
    "    \"Low Scoring Mutants\",\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"bottom\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbtest2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
